{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, make_scorer\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "\n",
    "# # Create an XGBoost classifier with specified parameters\n",
    "# model = xgb.XGBClassifier(\n",
    "#     n_estimators=1000,  # Number of trees in the forest\n",
    "#     gamma=1,  # Minimum loss reduction required to make a further partition on a leaf node\n",
    "#     learning_rate=1,  # Step size shrinkage used in update to prevent overfitting\n",
    "#     subsample=1,  # Subsample ratio of the training instances\n",
    "#     max_depth=4,  # Maximum depth of a tree\n",
    "# )\n",
    "\n",
    "# # Create a K-Fold cross-validation object with 5 splits\n",
    "# kfold = KFold(n_splits=10)\n",
    "\n",
    "# # Perform cross-validation and get the accuracy scores\n",
    "# result = cross_val_score(model, X=X, y=y, cv=kfold)\n",
    "\n",
    "# # Print the mean and standard deviation of the accuracy scores\n",
    "# print(\"Accuracy: %.2f%% (%.2f%%)\" % (result.mean() * 100, result.std() * 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modeling Data Dataset 2 (Tanpa Augmentasi)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noAug = pd.read_csv(\"../dataset/INA_TweetsPPKM_TFRF_DS2.csv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noAug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing cv in xgboost model\n",
    "df_noAug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_noAug.drop(\"sentiment\", axis=1)\n",
    "y = df_noAug[\"sentiment\"]\n",
    "print(X.shape, y.shape)\n",
    "X.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Testing Using Cross Validate Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBoost classifier with specified parameters\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,  # Number of trees in the forest\n",
    "    gamma=0.5,  # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    learning_rate=0.1,  # Step size shrinkage used in update to prevent overfitting\n",
    "    subsample=0.5,  # Subsample ratio of the training instances\n",
    "    max_depth=3,\n",
    "    nthread=4,\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision_macro\",\n",
    "    \"recall\": \"recall_macro\",\n",
    "}\n",
    "\n",
    "numFold = 3\n",
    "cv = StratifiedKFold(n_splits=numFold)\n",
    "\n",
    "\n",
    "results = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "accuracy_scores = results[\"test_accuracy\"]\n",
    "precision_scores = results[\"test_precision\"]\n",
    "recall_scores = results[\"test_recall\"]\n",
    "\n",
    "print(\"Cross-Validation Results:\")\n",
    "\n",
    "for i in range(numFold):\n",
    "    print(f\"Fold {i+1} : \")\n",
    "    print(\n",
    "        f\"Accuracy = {accuracy_scores[i]*100:.2f}% | Precision = {precision_scores[i]*100:.2f}% | Recall = {recall_scores[i]*100:.2f}%\\n\"\n",
    "    )\n",
    "print(\n",
    "    f\"Average Results : \\nAccuracy = {accuracy_scores.mean()*100:.2f}% | Precision = {precision_scores.mean()*100:.2f}% | Recall = {recall_scores.mean()*100:.2f}%\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Testing Using Combination Of Cross Validation And Gridsearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create an XGBoost classifier with specified parameters\n",
    "model = xgb.XGBClassifier(\n",
    "    gamma=0.5,  # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    subsample=0.5,  # Subsample ratio of the training instances\n",
    "    nthread=4,\n",
    ")\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision_macro\",\n",
    "    \"recall\": \"recall_macro\",\n",
    "}\n",
    "\n",
    "grid = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [3, 4],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.1],\n",
    "}\n",
    "\n",
    "numFold = 3\n",
    "cv = StratifiedKFold(n_splits=numFold)\n",
    "\n",
    "xgb_gr = GridSearchCV(\n",
    "    estimator=model, param_grid=grid, scoring=\"accuracy\", cv=cv, n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "results = cross_validate(xgb_gr, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "\n",
    "accuracy_scores = results[\"test_accuracy\"]\n",
    "precision_scores = results[\"test_precision\"]\n",
    "recall_scores = results[\"test_recall\"]\n",
    "print(xgb_gr.best_params_)\n",
    "print(accuracy_scores.mean())\n",
    "\n",
    "# print(\"Cross-Validation Results:\")\n",
    "\n",
    "# for i in range(numFold):\n",
    "#     print(f\"Fold {i+1} : \")\n",
    "#     print(\n",
    "#         f\"Accuracy = {accuracy_scores[i]*100:.2f}% | Precision = {precision_scores[i]*100:.2f}% | Recall = {recall_scores[i]*100:.2f}%\\n\"\n",
    "#     )\n",
    "# print(\n",
    "#     f\"Average Results : \\nAccuracy = {accuracy_scores.mean()*100:.2f}% | Precision = {precision_scores.mean()*100:.2f}% | Recall = {recall_scores.mean()*100:.2f}%\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBoost classifier with specified parameters\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,  # Number of trees in the forest\n",
    "    gamma=1,  # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    learning_rate=1,  # Step size shrinkage used in update to prevent overfitting\n",
    "    subsample=1,  # Subsample ratio of the training instances\n",
    "    max_depth=4,  # Maximum depth of a tree\n",
    ")\n",
    "\n",
    "# Create a K-Fold cross-validation object with 5 splits\n",
    "kfold_1 = KFold(n_splits=5)\n",
    "SKFold_1 = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Perform cross-validation and get the accuracy scores\n",
    "accuracy_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"accuracy\")\n",
    "precision_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"precision_macro\")\n",
    "recall_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"recall_macro\")\n",
    "\n",
    "# Print the mean and standard deviation of the scores\n",
    "print(\n",
    "    \"Accuracy: {:.2f} (+/- {:.2f})\".format(\n",
    "        accuracy_scores.mean(), accuracy_scores.std() * 2\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Precision: {:.2f} (+/- {:.2f})\".format(\n",
    "        precision_scores.mean(), precision_scores.std() * 2\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Recall: {:.2f} (+/- {:.2f})\".format(recall_scores.mean(), recall_scores.std() * 2)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XGBoost classifier with specified parameters\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,  # Number of trees in the forest\n",
    "    gamma=1,  # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    learning_rate=1,  # Step size shrinkage used in update to prevent overfitting\n",
    "    subsample=1,  # Subsample ratio of the training instances\n",
    "    max_depth=4,  # Maximum depth of a tree\n",
    ")\n",
    "\n",
    "# Create a K-Fold cross-validation object with 5 splits\n",
    "numFold = 5\n",
    "kfold_1 = KFold(n_splits=5)\n",
    "SKFold_1 = StratifiedKFold(n_splits=numFold, random_state=42, shuffle=True)\n",
    "\n",
    "accuracy_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"accuracy\")\n",
    "precision_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"precision_macro\")\n",
    "recall_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"recall_macro\")\n",
    "\n",
    "\n",
    "for i in range(numFold):\n",
    "    print(\n",
    "        f\"Fold {i+1} : Accuracy = {accuracy_scores[i] * 100:.2f}% | Precision : {precision_scores[i]*100:.2f}% | Recall = {recall_scores[i]*100:.2f}% \\n\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Average Scores : Accuracy = {accuracy_scores.mean()*100:.2f}% ({accuracy_scores.std()*100:.2f}%) | Precision = {precision_scores.mean()*100:.2f}% | Recall = {recall_scores.mean()*100:.2f}%\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10)\n",
    "SKFold_2 = StratifiedKFold(n_splits=10)\n",
    "result2 = cross_val_score(model, X=X, y=y, cv=SKFold_2)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (result2.mean() * 100, result2.std() * 100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modeling Data Dataset 3 (Augmentasi)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/INA_TweetsPPKM_TFRF_DS3.csv\", sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing cv in xgboost model\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"sentiment\", axis=1)\n",
    "y = df[\"sentiment\"]\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "# Create an XGBoost classifier with specified parameters\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=1000,  # Number of trees in the forest\n",
    "    gamma=0.5,  # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    learning_rate=0.1,  # Step size shrinkage used in update to prevent overfitting\n",
    "    subsample=0.5,  # Subsample ratio of the training instances\n",
    "    max_depth=4,  # Maximum depth of a tree\n",
    "\n",
    ")\n",
    "\n",
    "numFold = 5\n",
    "kfold_1 = KFold(n_splits=5)\n",
    "SKFold_1 = StratifiedKFold(n_splits=numFold, random_state=42, shuffle=True)\n",
    "\n",
    "accuracy_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"accuracy\")\n",
    "precision_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"precision_macro\")\n",
    "recall_scores = cross_val_score(model, X, y, cv=SKFold_1, scoring=\"recall_macro\")\n",
    "\n",
    "\n",
    "for i in range(numFold):\n",
    "    print(\n",
    "        f\"Fold {i+1} : Accuracy = {accuracy_scores[i] * 100:.2f}% | Precision : {precision_scores[i]*100:.2f}% | Recall = {recall_scores[i]*100:.2f}% \\n\"\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\"Average Scores : Accuracy = {accuracy_scores.mean()*100:.2f}% ({accuracy_scores.std()*100:.2f}%) | Precision = {precision_scores.mean()*100:.2f}% | Recall = {recall_scores.mean()*100:.2f}%\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10)\n",
    "SKFold2 = StratifiedKFold(n_splits=10)\n",
    "result2 = cross_val_score(model, X=X, y=y, cv=SKFold2)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (result2.mean() * 100, result2.std() * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
